dataset_path: /data/unagi0/noguchi/dataset/rendered_shapenet/car_iclr_final
image_path: /data/unagi0/noguchi/dataset/rendered_shapenet/car_iclr_final/*.png

nvprof: False
seed: 19260817
adam_alpha_g: 0.001 # 'alpha in Adam optimizer')
adam_alpha_d: 0.003 # 'alpha in Adam optimizer')
adam_beta1: 0.0 # 'beta1 in Adam optimizer')
adam_beta2: 0.999 # 'beta2 in Adam optimizer')
lambda_gp: 1.0 #'Lambda GP')
sn: False
smoothing: 0.999 # '')
keep_smoothed_gen: False # 'Whether to keep a smoothed version of generator.')
dynamic_batch_size: '16,16,16,16,16,16,16,16,16,8,8,4,4,2,2,1,1'
#                     'comma-split list of dynamic batch size w.p.t. stage')
batchsize: 32
stage_interval: 0,0,0,0,0,0,0,100000, 150000, 160000, 180000, 1000000
max_stage: 11 # 'Size of image.')
iteration: 1000000
#
start_rotation: 2000
start_occlusion_aware: 2000
#
auto_resume: False # 'Whether to automatically resume')
#
ch: 256 # '#Channels')
debug_start_instance: 0 # 'Change starting iteration for debugging.')
#
## architecture
generator_architecture: dcgan # stylegan, dcgan, deepvoxels
bigan: False
rotate_conv_input: False
res_dis: True
focal_loss_gamma: 1.
lambda_depth: 10
depth_min: 0.6
lambda_geometric: 1

## use camera parameter's posterior
use_posterior: False

## camera parameter prior
## rotation angle range (+-radian)
x_rotate: 0.3054
y_rotate: 3.1415
z_rotate: 0
# translation range
x_translate: 0
y_translate: 0
z_translate: 0

# test angles
test_x_rotate: 0
test_y_rotate: 3.1415
test_z_rotate: 0
test_x_translate: 0
test_y_translate: 0
test_z_translate: 0

## hps (device)
gpu: 1 # 'GPU ID (negative value indicates CPU)')
use_mpi: False # 'Whether to use MPI for multi-GPU training.')
comm_name: 'pure_nccl' # 'ChainerMN communicator name')
enable_cuda_profiling: False # 'Whether to enable CUDA profiling.')
train_img_list: "img_list.txt"  # paths to training images
#
#
## hps (I/O)
out: '/data/unagi0/noguchi/M2/RGB_synthesis/test' # 'Directory to output the result')
auto_resume_dir: '' # 'Directory for loading the saved models')
dataset_config: '' # 'Dataset config json')

dataset_worker_num': 12 # 'Number of threads in dataset loader'
#
snapshot_interval: 10000 # 'Interval of snapshot')
evaluation_sample_interval: 500 # 'Interval of evaluation sampling')
display_interval: 100 # 'Interval of displaying log to console')
get_model_from_interation: '' # 'Load this iteration (it is a string)')
#
## hps FID
fid_interval: 0 # 'Enable FID when > 0')
fid_real_stat: '' # 'Save NPZ of real images')
fid_clfs_type: '' # 'i2v_v5/inception')
fid_clfs_path: '' # 'classifier path')
fid_skip_first: False # 'Whether to skip FID calculation when iter = 0')
#
## Style GAN
style_mixing_rate: 0.0 # ' Style Mixing Prob')
enable_blur: False # 'Enable blur function after upscaling/downscaling')


stage2reso:
  0: 4
  1: 8
  2: 8
  3: 16
  4: 16
  5: 32
  6: 32
  7: 64
  8: 64
  9: 128
  10: 128
  11: 256
  12: 256
  13: 512
  14: 512
  15: 1024
  16: 1024
  17: 1024

gpu_lr:
  1: {15: 1.5, 16: 1.5, 17: 1.5}
  2: {13: 1.5, 14: 1.5, 15: 2, 16: 2, 17: 2}
  3: {11: 1.5, 12: 1.5, 13: 2, 14: 2, 15: 2.5, 16: 2.5, 17: 2.5}
  4: {11: 1.5, 12: 1.5, 13: 2, 14: 2, 15: 3, 16: 3, 17: 3}
  8: {9: 1.5, 10: 1.5, 11: 2, 12: 2, 13: 3, 14: 3, 15: 3, 16: 3, 17: 3}